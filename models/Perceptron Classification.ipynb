{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import ascii_uppercase\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Reformat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/220720PM25diffsite.csv\"\n",
    "output_file = \"../result/gpr_all_features.csv\"\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "selected_features = [\"pm25\", \"ENSOmonthly\"\n",
    "           ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "           ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "           ,\"dayofweekf\",\"dayofyear\"]\n",
    "all_features = [\"pm25\", \"ENSOmonthly\"\n",
    "              ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "              ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "              ,\"dayofweekf\",\"dayofyear\"\n",
    "              ,\"MirTemp500C\",\"MirWS850ms\",\"MirWD850\",\"MirHeight850\",\"MirWS500ms\",\"MirWD500\",\"Mir500RH\"\n",
    "              ,\"SRmeanC\",\"AWNDbarstow\",\"TMAXLAX\",\"TMAXontario\",\"AWNDontario\"]\n",
    "df_selected = df[selected_features]\n",
    "df_all_features = df[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_all_features.dropna()\n",
    "label_name = \"pm25\"\n",
    "y_vector = dataset[[label_name]]\n",
    "# change it for all features or selected features\n",
    "# features_names = all_features.copy()\n",
    "features_names = selected_features.copy()\n",
    "features_names.remove(label_name)\n",
    "X_matrix = dataset[features_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ENSOmonthly      eNOx  SO2emis  PM25emis     eVOC  NH3emis  TMAXbarstow  \\\n",
      "3           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "4           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "6           24.78  1007.938   62.837    78.766  999.205   94.759         13.3   \n",
      "8           24.78  1007.938   62.837    78.766  999.205   94.759         18.3   \n",
      "9           24.78  1007.938   62.837    78.766  999.205   94.759         23.9   \n",
      "...           ...       ...      ...       ...      ...      ...          ...   \n",
      "7299        27.07   337.141   16.174    81.619  526.083   79.151          7.0   \n",
      "7300        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7301        27.07   337.141   16.174    81.619  526.083   79.151         11.0   \n",
      "7302        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7303        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "\n",
      "      AWNDLAX   Mir850RH  Rhontario  dayofweekf  dayofyear  \n",
      "3         2.8  23.944355  42.057143           2          4  \n",
      "4         2.4  29.298520  46.566667           3          5  \n",
      "6         2.5  16.740247  13.825000           5          7  \n",
      "8         2.0  22.701877  35.786957           7          9  \n",
      "9         2.3  35.159068  50.939130           1         10  \n",
      "...       ...        ...        ...         ...        ...  \n",
      "7299      3.7  93.850898  78.000000           4        360  \n",
      "7300      2.7  60.405744  60.000000           5        361  \n",
      "7301      2.1  41.563683  67.000000           6        362  \n",
      "7302      1.8  42.263233  63.000000           7        363  \n",
      "7303      2.6  48.585748  42.000000           1        364  \n",
      "\n",
      "[5465 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "def dayofweekToNum(data_frame):\n",
    "    day_mapping = {\"Mon\": 1, \"Tue\": 2, \"Wed\": 3, \"Thu\": 4, \"Fri\": 5, \"Sat\": 6, \"Sun\": 7}\n",
    "    dayofweekf = data_frame[\"dayofweekf\"].to_numpy()\n",
    "    res = []\n",
    "    for i in range(0, len(dayofweekf)):\n",
    "        res.append(day_mapping[dayofweekf[i]])\n",
    "    data_frame.loc[:, (\"dayofweekf\")] = res\n",
    "    return data_frame\n",
    "X_matrix = dayofweekToNum(X_matrix)\n",
    "print(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 12\n",
    "threshold = 25\n",
    "features_data = X_matrix.to_numpy()\n",
    "_, num_features = features_data.shape\n",
    "label_data = y_vector.to_numpy()\n",
    "# split the data for 10-fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=100)\n",
    "classified_label = np.zeros(label_data.shape)\n",
    "classified_label[label_data >= threshold] = 1\n",
    "label_data = classified_label.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after tuning none penalty is best\n",
    "penalty = None\n",
    "alphas = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "testing_data_rows = []\n",
    "training_data_rows = []\n",
    "final_accuracy = None\n",
    "final_precision = None\n",
    "final_f1 = None\n",
    "final_pod = None\n",
    "final_ftp = None\n",
    "final_prediction = None\n",
    "for alpha in alphas:\n",
    "    accuracy_testing = []\n",
    "    precision_testing = []\n",
    "    f1_testing = []\n",
    "    pod_testing = []\n",
    "    ftp_testing = []\n",
    "    \n",
    "    accuracy_training = []\n",
    "    precision_training = []\n",
    "    f1_training = []\n",
    "    pod_training = []\n",
    "    ftp_training = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features_data):\n",
    "        X_train, X_test = features_data[train_index], features_data[test_index]\n",
    "        y_train, y_test = label_data[train_index], label_data[test_index]\n",
    "        model = Perceptron(penalty=penalty, \n",
    "                           alpha=alpha, \n",
    "                           fit_intercept=True, \n",
    "                           max_iter=5000,\n",
    "                           random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model performance\n",
    "        # test data\n",
    "        predict_res = model.predict(X_test)\n",
    "        accuracy_testing.append(accuracy_score(y_test, predict_res))\n",
    "        precision_testing.append(precision_score(y_test, predict_res))\n",
    "        f1_testing.append(f1_score(y_test, predict_res))\n",
    "        pod_testing.append(recall_score(y_test, predict_res))\n",
    "        ftp_testing.append(1 - recall_score(y_test, predict_res))\n",
    "        \n",
    "        # training data\n",
    "        predict_res = model.predict(X_train)\n",
    "        accuracy_training.append(accuracy_score(y_train, predict_res))\n",
    "        precision_training.append(precision_score(y_train, predict_res))\n",
    "        f1_training.append(f1_score(y_train, predict_res))\n",
    "        pod_training.append(recall_score(y_train, predict_res))\n",
    "        ftp_training.append(1 - recall_score(y_train, predict_res))\n",
    "\n",
    "    # write down the performance for current hyperparameters\n",
    "    accuracy_mean = np.mean(accuracy_testing)\n",
    "    precision_mean = np.mean(precision_testing)\n",
    "    f1_mean = np.mean(f1_testing)\n",
    "    pod_mean = np.mean(pod_testing)\n",
    "    ftp_mean = np.mean(ftp_testing)\n",
    "    data_row = [alpha, accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    testing_data_rows.append(data_row)\n",
    "    \n",
    "    accuracy_mean = np.mean(accuracy_training)\n",
    "    precision_mean = np.mean(precision_training)\n",
    "    f1_mean = np.mean(f1_training)\n",
    "    pod_mean = np.mean(pod_training)\n",
    "    ftp_mean = np.mean(ftp_training)\n",
    "    data_row = [alpha, accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    training_data_rows.append(data_row)\n",
    "    \n",
    "    # train by all data\n",
    "    model = Perceptron(penalty=penalty, \n",
    "                   alpha=alpha, \n",
    "                   fit_intercept=True, \n",
    "                   max_iter=5000,\n",
    "                   random_state=0)\n",
    "    model.fit(features_data, label_data)\n",
    "    # evaluate the model performance\n",
    "    predict_res = model.predict(features_data)\n",
    "    final_accuracy = accuracy_score(label_data, predict_res)\n",
    "    final_precision = precision_score(label_data, predict_res)\n",
    "    final_f1 = f1_score(label_data, predict_res)\n",
    "    final_pod = recall_score(label_data, predict_res)\n",
    "    final_ftp = 1 - recall_score(label_data, predict_res)\n",
    "    \n",
    "    final_prediction = predict_res\n",
    "\n",
    "# clf = Perceptron(penalty=None,\n",
    "    #                  alpha=0.0001,\n",
    "    #                  l1_ratio=0.15,\n",
    "    #                  fit_intercept=True,\n",
    "    #                  max_iter=1000,\n",
    "    #                  tol=0.001,\n",
    "    #                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.000000   accuracy = 0.801808   precision = 0.506452   f1 = 0.275175   POD = 0.344801   FTP = 0.655199\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(testing_data_rows)):\n",
    "    print(\"alpha = %f   accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(training_data_rows[i][0], training_data_rows[i][1], \n",
    "        training_data_rows[i][2], training_data_rows[i][3],\n",
    "        training_data_rows[i][4], training_data_rows[i][5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "accuracy = 0.801808   precision = 0.506452   f1 = 0.275175   POD = 0.344801   FTP = 0.655199\n",
      "Testing Data\n",
      "accuracy = 0.798914   precision = 0.546075   f1 = 0.268443   POD = 0.336249   FTP = 0.663751\n"
     ]
    }
   ],
   "source": [
    "# for Table S4\n",
    "print(\"Training Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(training_data_rows[0][1], training_data_rows[0][2], \n",
    "        training_data_rows[0][3], training_data_rows[0][4],\n",
    "        training_data_rows[0][5]))\n",
    "print(\"Testing Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(testing_data_rows[0][1], testing_data_rows[0][2], \n",
    "        testing_data_rows[0][3], testing_data_rows[0][4],\n",
    "        testing_data_rows[0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.810064   precision = 0.600000   f1 = 0.005747   POD = 0.002887   FTP = 0.997113\n"
     ]
    }
   ],
   "source": [
    "# for Table 1\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\"    \n",
    "      %(final_accuracy, final_precision, final_f1, final_pod, final_ftp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Annual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-exc</th>\n",
       "      <th>Exc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-exc</th>\n",
       "      <td>4424</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exc</th>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Non-exc  Exc\n",
       "Non-exc     4424    2\n",
       "Exc         1036    3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matricies=confusion_matrix(label_data, final_prediction)\n",
    "columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(label_data))]]\n",
    "columns=['Non-exc','Exc']\n",
    "# columns=['Non Exceedance', 'Exceedance']\n",
    "df_cm = pd.DataFrame(confusion_matricies, index=columns, columns=columns)\n",
    "df_cm\n",
    "# ax=sn.heatmap(df_cm,cmap='Oranges',annot=True,fmt='g',cbar_kws={'label': 'Occurrences'})\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix for ' + \"Perceptron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
