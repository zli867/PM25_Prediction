{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Reformat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/220720PM25diffsite.csv\"\n",
    "output_file = \"../result/nn_selected_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"pm25\", \"ENSOmonthly\"\n",
    "           ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "           ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "           ,\"dayofweekf\",\"dayofyear\"]\n",
    "all_features = [\"pm25\", \"ENSOmonthly\"\n",
    "              ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "              ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "              ,\"dayofweekf\",\"dayofyear\"\n",
    "              ,\"MirTemp500C\",\"MirWS850ms\",\"MirWD850\",\"MirHeight850\",\"MirWS500ms\",\"MirWD500\",\"Mir500RH\"\n",
    "              ,\"SRmeanC\",\"AWNDbarstow\",\"TMAXLAX\",\"TMAXontario\",\"AWNDontario\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_features = df[all_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide the features (for all features or selected features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_all_features.dropna()\n",
    "label_name = \"pm25\"\n",
    "y_vector = dataset[[label_name]]\n",
    "# change it for all features or selected features\n",
    "# features_names = all_features.copy()\n",
    "features_names = selected_features.copy()\n",
    "features_names.remove(label_name)\n",
    "X_matrix = dataset[features_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ENSOmonthly      eNOx  SO2emis  PM25emis     eVOC  NH3emis  TMAXbarstow  \\\n",
      "3           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "4           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "6           24.78  1007.938   62.837    78.766  999.205   94.759         13.3   \n",
      "8           24.78  1007.938   62.837    78.766  999.205   94.759         18.3   \n",
      "9           24.78  1007.938   62.837    78.766  999.205   94.759         23.9   \n",
      "...           ...       ...      ...       ...      ...      ...          ...   \n",
      "7299        27.07   337.141   16.174    81.619  526.083   79.151          7.0   \n",
      "7300        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7301        27.07   337.141   16.174    81.619  526.083   79.151         11.0   \n",
      "7302        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7303        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "\n",
      "      AWNDLAX   Mir850RH  Rhontario dayofweekf  dayofyear  \n",
      "3         2.8  23.944355  42.057143        Tue          4  \n",
      "4         2.4  29.298520  46.566667        Wed          5  \n",
      "6         2.5  16.740247  13.825000        Fri          7  \n",
      "8         2.0  22.701877  35.786957        Sun          9  \n",
      "9         2.3  35.159068  50.939130        Mon         10  \n",
      "...       ...        ...        ...        ...        ...  \n",
      "7299      3.7  93.850898  78.000000        Thu        360  \n",
      "7300      2.7  60.405744  60.000000        Fri        361  \n",
      "7301      2.1  41.563683  67.000000        Sat        362  \n",
      "7302      1.8  42.263233  63.000000        Sun        363  \n",
      "7303      2.6  48.585748  42.000000        Mon        364  \n",
      "\n",
      "[5465 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "def dayofweekToNum(data_frame):\n",
    "    day_mapping = {\"Mon\": 1, \"Tue\": 2, \"Wed\": 3, \"Thu\": 4, \"Fri\": 5, \"Sat\": 6, \"Sun\": 7}\n",
    "    dayofweekf = data_frame[\"dayofweekf\"].to_numpy()\n",
    "    res = []\n",
    "    for i in range(0, len(dayofweekf)):\n",
    "        res.append(day_mapping[dayofweekf[i]])\n",
    "    data_frame.loc[:, (\"dayofweekf\")] = res\n",
    "    return data_frame\n",
    "print(X_matrix)\n",
    "X_matrix = dayofweekToNum(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 12\n",
    "# threshold = 35\n",
    "# threshold = 20\n",
    "threshold = 12\n",
    "features_data = X_matrix.to_numpy()\n",
    "_, num_features = features_data.shape\n",
    "label_data = y_vector.to_numpy()\n",
    "# split the data for 10-fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=100)\n",
    "classified_label = np.zeros(label_data.shape)\n",
    "classified_label[label_data >= threshold] = 1\n",
    "label_data = classified_label.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE ACTIVATION FUNCTION\n",
    "# ACTIVATION = torch.tanh\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features, num_layers, num_hiddens, ACTIVATION):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.fcs = []\n",
    "        self.activate = ACTIVATION\n",
    "        # Define input layer\n",
    "        self.input_fc = nn.Linear(num_features, num_hiddens)\n",
    "        # Define hidden layers\n",
    "        for i in range(0, num_layers):\n",
    "            fc = nn.Linear(num_hiddens, num_hiddens)\n",
    "            setattr(self, 'fc%i' % i, fc)\n",
    "            self.fcs.append(fc)\n",
    "        # Define output layers\n",
    "        self.output_layer = nn.Linear(num_hiddens, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_fc(x)\n",
    "        for i in range(0, self.num_layers):\n",
    "            x = self.fcs[i](x)\n",
    "            x = self.activate(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "def loss_func(model, features, true_values):\n",
    "    predict_values = model.forward(features)\n",
    "    res = loss_function(predict_values, true_values)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "ReLU activation function, 3 hidden layers, 40 neuron for each hidden layers; 5000 training batch; Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters and net\n",
    "ACTIVATION = torch.relu\n",
    "# select feature 3 layers and 40 nodes; all feature 2 layer and 60 nodes\n",
    "net_parameters = [(3, 40)]\n",
    "max_iter = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3987, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3672, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "features_data = torch.from_numpy(features_data).float()\n",
    "label_data = torch.from_numpy(label_data).long()\n",
    "testing_data_rows = []\n",
    "training_data_rows = []\n",
    "final_accuracy = None\n",
    "final_precision = None\n",
    "final_f1 = None\n",
    "final_pod = None\n",
    "final_ftp = None\n",
    "final_prediction = None\n",
    "for net_parameter in net_parameters:\n",
    "    accuracy_testing = []\n",
    "    precision_testing = []\n",
    "    f1_testing = []\n",
    "    pod_testing = []\n",
    "    ftp_testing = []\n",
    "    \n",
    "    accuracy_training = []\n",
    "    precision_training = []\n",
    "    f1_training = []\n",
    "    pod_training = []\n",
    "    ftp_training = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features_data):\n",
    "        # build the net\n",
    "        net = NeuralNetwork(num_features, net_parameter[0], net_parameter[1], ACTIVATION)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "        X_train, X_test = features_data[train_index], features_data[test_index]\n",
    "        y_train, y_test = label_data[train_index], label_data[test_index]\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            loss = loss_func(net, X_train, y_train)\n",
    "            optimizer.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "            loss.backward() #backprop\n",
    "            optimizer.step()\n",
    "        print(loss)\n",
    "        # evaluate the model r2 using test data set, etc.\n",
    "        net.eval()\n",
    "        # test data performance\n",
    "        predict_res = net(X_test)\n",
    "        _, predict_res = torch.max(predict_res, 1)\n",
    "        predict_res = predict_res.detach().numpy()\n",
    "        accuracy_testing.append(accuracy_score(y_test, predict_res))\n",
    "        precision_testing.append(precision_score(y_test, predict_res))\n",
    "        f1_testing.append(f1_score(y_test, predict_res))\n",
    "        pod_testing.append(recall_score(y_test, predict_res))\n",
    "        ftp_testing.append(1 - recall_score(y_test, predict_res))\n",
    "        \n",
    "        # training data performance\n",
    "        predict_res = net(X_train)\n",
    "        _, predict_res = torch.max(predict_res, 1)\n",
    "        predict_res = predict_res.detach().numpy()\n",
    "        accuracy_training.append(accuracy_score(y_train, predict_res))\n",
    "        precision_training.append(precision_score(y_train, predict_res))\n",
    "        f1_training.append(f1_score(y_train, predict_res))\n",
    "        pod_training.append(recall_score(y_train, predict_res))\n",
    "        ftp_training.append(1 - recall_score(y_train, predict_res))\n",
    "        \n",
    "    # write down the performance for current hyperparameters\n",
    "    accuracy_mean = np.mean(accuracy_testing)\n",
    "    precision_mean = np.mean(precision_testing)\n",
    "    f1_mean = np.mean(f1_testing)\n",
    "    pod_mean = np.mean(pod_testing)\n",
    "    ftp_mean = np.mean(ftp_testing)\n",
    "    data_row = [net_parameter[0], net_parameter[1], accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    testing_data_rows.append(data_row)\n",
    "    \n",
    "    accuracy_mean = np.mean(accuracy_training)\n",
    "    precision_mean = np.mean(precision_training)\n",
    "    f1_mean = np.mean(f1_training)\n",
    "    pod_mean = np.mean(pod_training)\n",
    "    ftp_mean = np.mean(ftp_training)\n",
    "    data_row = [net_parameter[0], net_parameter[1], accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    training_data_rows.append(data_row)\n",
    "    \n",
    "    # train by all data\n",
    "    net = NeuralNetwork(num_features, net_parameter[0], net_parameter[1], ACTIVATION)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "    for i in range(max_iter):\n",
    "        loss = loss_func(net, features_data, label_data)\n",
    "        optimizer.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "        loss.backward() #backprop\n",
    "        optimizer.step()\n",
    "    net.eval()\n",
    "    # evaluate the model performance\n",
    "    predict_res = net(features_data)\n",
    "    _, predict_res = torch.max(predict_res, 1)\n",
    "    predict_res = predict_res.detach().numpy()\n",
    "    final_accuracy = accuracy_score(label_data, predict_res)\n",
    "    final_precision = precision_score(label_data, predict_res)\n",
    "    final_f1 = f1_score(label_data, predict_res)\n",
    "    final_pod = recall_score(label_data, predict_res)\n",
    "    final_ftp = 1 - recall_score(label_data, predict_res)\n",
    "    \n",
    "    final_prediction = predict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "accuracy = 0.824703   precision = 0.843813   f1 = 0.857216   POD = 0.871854   FTP = 0.128146\n",
      "Testing Data\n",
      "accuracy = 0.796516   precision = 0.823056   f1 = 0.833173   POD = 0.844781   FTP = 0.155219\n"
     ]
    }
   ],
   "source": [
    "# for Table S4\n",
    "print(\"Training Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(training_data_rows[0][2], training_data_rows[0][3], \n",
    "        training_data_rows[0][4], training_data_rows[0][5],\n",
    "        training_data_rows[0][6]))\n",
    "print(\"Testing Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(testing_data_rows[0][2], testing_data_rows[0][3], \n",
    "        testing_data_rows[0][4], testing_data_rows[0][5],\n",
    "        testing_data_rows[0][6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.830924   precision = 0.867761   f1 = 0.858456   POD = 0.849348   FTP = 0.150652\n"
     ]
    }
   ],
   "source": [
    "# for Table 1\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\"    \n",
    "      %(final_accuracy, final_precision, final_f1, final_pod, final_ftp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-exc</th>\n",
       "      <th>Exc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-exc</th>\n",
       "      <td>1739</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exc</th>\n",
       "      <td>497</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Non-exc   Exc\n",
       "Non-exc     1739   427\n",
       "Exc          497  2802"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matricies=confusion_matrix(label_data, final_prediction)\n",
    "columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(label_data))]]\n",
    "columns=['Non-exc','Exc']\n",
    "# columns=['Non Exceedance', 'Exceedance']\n",
    "df_cm = pd.DataFrame(confusion_matricies, index=columns, columns=columns)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (input_fc): Linear(in_features=12, out_features=40, bias=True)\n",
       "  (fc0): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (fc1): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (fc2): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (output_layer): Linear(in_features=40, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
