{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bff5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF, ConstantKernel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c9d9f",
   "metadata": {},
   "source": [
    "## Read and Reformat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6884d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/220720PM25diffsite.csv\"\n",
    "output_file = \"../result/gpr_all_features.csv\"\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "selected_features = [\"pm25\", \"ENSOmonthly\"\n",
    "           ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "           ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "           ,\"dayofweekf\",\"dayofyear\"]\n",
    "all_features = [\"pm25\", \"ENSOmonthly\"\n",
    "              ,\"eNOx\",\"SO2emis\",\"PM25emis\",\"eVOC\",\"NH3emis\"\n",
    "              ,\"TMAXbarstow\",\"AWNDLAX\",\"Mir850RH\",\"Rhontario\"\n",
    "              ,\"dayofweekf\",\"dayofyear\"\n",
    "              ,\"MirTemp500C\",\"MirWS850ms\",\"MirWD850\",\"MirHeight850\",\"MirWS500ms\",\"MirWD500\",\"Mir500RH\"\n",
    "              ,\"SRmeanC\",\"AWNDbarstow\",\"TMAXLAX\",\"TMAXontario\",\"AWNDontario\"]\n",
    "df_selected = df[selected_features]\n",
    "df_all_features = df[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efbfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_all_features.dropna()\n",
    "label_name = \"pm25\"\n",
    "y_vector = dataset[[label_name]]\n",
    "# change it for all features or selected features\n",
    "# features_names = all_features.copy()\n",
    "features_names = selected_features.copy()\n",
    "features_names.remove(label_name)\n",
    "X_matrix = dataset[features_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc9610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ENSOmonthly      eNOx  SO2emis  PM25emis     eVOC  NH3emis  TMAXbarstow  \\\n",
      "3           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "4           24.78  1007.938   62.837    78.766  999.205   94.759         16.7   \n",
      "6           24.78  1007.938   62.837    78.766  999.205   94.759         13.3   \n",
      "8           24.78  1007.938   62.837    78.766  999.205   94.759         18.3   \n",
      "9           24.78  1007.938   62.837    78.766  999.205   94.759         23.9   \n",
      "...           ...       ...      ...       ...      ...      ...          ...   \n",
      "7299        27.07   337.141   16.174    81.619  526.083   79.151          7.0   \n",
      "7300        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7301        27.07   337.141   16.174    81.619  526.083   79.151         11.0   \n",
      "7302        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "7303        27.07   337.141   16.174    81.619  526.083   79.151          9.0   \n",
      "\n",
      "      AWNDLAX   Mir850RH  Rhontario  dayofweekf  dayofyear  \n",
      "3         2.8  23.944355  42.057143           2          4  \n",
      "4         2.4  29.298520  46.566667           3          5  \n",
      "6         2.5  16.740247  13.825000           5          7  \n",
      "8         2.0  22.701877  35.786957           7          9  \n",
      "9         2.3  35.159068  50.939130           1         10  \n",
      "...       ...        ...        ...         ...        ...  \n",
      "7299      3.7  93.850898  78.000000           4        360  \n",
      "7300      2.7  60.405744  60.000000           5        361  \n",
      "7301      2.1  41.563683  67.000000           6        362  \n",
      "7302      1.8  42.263233  63.000000           7        363  \n",
      "7303      2.6  48.585748  42.000000           1        364  \n",
      "\n",
      "[5465 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongrunli/opt/anaconda3/envs/Data_Analysis/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "def dayofweekToNum(data_frame):\n",
    "    day_mapping = {\"Mon\": 1, \"Tue\": 2, \"Wed\": 3, \"Thu\": 4, \"Fri\": 5, \"Sat\": 6, \"Sun\": 7}\n",
    "    dayofweekf = data_frame[\"dayofweekf\"].to_numpy()\n",
    "    res = []\n",
    "    for i in range(0, len(dayofweekf)):\n",
    "        res.append(day_mapping[dayofweekf[i]])\n",
    "    data_frame.loc[:, (\"dayofweekf\")] = res\n",
    "    return data_frame\n",
    "X_matrix = dayofweekToNum(X_matrix)\n",
    "print(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3359e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 12\n",
    "# threshold = 35\n",
    "threshold = 25\n",
    "features_data = X_matrix.to_numpy()\n",
    "_, num_features = features_data.shape\n",
    "label_data = y_vector.to_numpy()\n",
    "# split the data for 10-fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=100)\n",
    "classified_label = np.zeros(label_data.shape)\n",
    "classified_label[label_data >= threshold] = 1\n",
    "label_data = classified_label.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cbe4c",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64718da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for selected feature 19, 105, for all feature we still use 19, 105\n",
    "hyper_parameters = [(19, 105)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd118def",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_rows = []\n",
    "training_data_rows = []\n",
    "final_accuracy = None\n",
    "final_precision = None\n",
    "final_f1 = None\n",
    "final_pod = None\n",
    "final_ftp = None\n",
    "final_prediction = None\n",
    "for hyper_parameter in hyper_parameters:\n",
    "    accuracy_testing = []\n",
    "    precision_testing = []\n",
    "    f1_testing = []\n",
    "    pod_testing = []\n",
    "    ftp_testing = []\n",
    "    \n",
    "    accuracy_training = []\n",
    "    precision_training = []\n",
    "    f1_training = []\n",
    "    pod_training = []\n",
    "    ftp_training = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features_data):\n",
    "        X_train, X_test = features_data[train_index], features_data[test_index]\n",
    "        y_train, y_test = label_data[train_index], label_data[test_index]\n",
    "        kernel = ConstantKernel(hyper_parameter[0], 'fixed') * RBF(hyper_parameter[1], 'fixed')\n",
    "        model = GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=1, random_state=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model performance\n",
    "        # test data\n",
    "        predict_res = model.predict(X_test)\n",
    "        accuracy_testing.append(accuracy_score(y_test, predict_res))\n",
    "        precision_testing.append(precision_score(y_test, predict_res))\n",
    "        f1_testing.append(f1_score(y_test, predict_res))\n",
    "        pod_testing.append(recall_score(y_test, predict_res))\n",
    "        ftp_testing.append(1 - recall_score(y_test, predict_res))\n",
    "        \n",
    "        # training data\n",
    "        predict_res = model.predict(X_train)\n",
    "        accuracy_training.append(accuracy_score(y_train, predict_res))\n",
    "        precision_training.append(precision_score(y_train, predict_res))\n",
    "        f1_training.append(f1_score(y_train, predict_res))\n",
    "        pod_training.append(recall_score(y_train, predict_res))\n",
    "        ftp_training.append(1 - recall_score(y_train, predict_res))\n",
    "\n",
    "    # write down the performance for current hyperparameters\n",
    "    accuracy_mean = np.mean(accuracy_testing)\n",
    "    precision_mean = np.mean(precision_testing)\n",
    "    f1_mean = np.mean(f1_testing)\n",
    "    pod_mean = np.mean(pod_testing)\n",
    "    ftp_mean = np.mean(ftp_testing)\n",
    "    data_row = [hyper_parameter[0], hyper_parameter[1], accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    testing_data_rows.append(data_row)\n",
    "    \n",
    "    accuracy_mean = np.mean(accuracy_training)\n",
    "    precision_mean = np.mean(precision_training)\n",
    "    f1_mean = np.mean(f1_training)\n",
    "    pod_mean = np.mean(pod_training)\n",
    "    ftp_mean = np.mean(ftp_training)\n",
    "    data_row = [hyper_parameter[0], hyper_parameter[1], accuracy_mean, precision_mean, f1_mean, pod_mean, ftp_mean]\n",
    "    training_data_rows.append(data_row)\n",
    "    \n",
    "    # train by all data\n",
    "    kernel = ConstantKernel(hyper_parameter[0], 'fixed') * RBF(hyper_parameter[1], 'fixed')\n",
    "    model = GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=1)\n",
    "    model.fit(features_data, label_data)\n",
    "    # evaluate the model performance\n",
    "    predict_res = model.predict(features_data)\n",
    "    final_accuracy = accuracy_score(label_data, predict_res)\n",
    "    final_precision = precision_score(label_data, predict_res)\n",
    "    final_f1 = f1_score(label_data, predict_res)\n",
    "    final_pod = recall_score(label_data, predict_res)\n",
    "    final_ftp = 1 - recall_score(label_data, predict_res)\n",
    "    \n",
    "    final_prediction = predict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e1126",
   "metadata": {},
   "source": [
    "## Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998e3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "accuracy = 0.897448   precision = 0.793648   f1 = 0.697651   POD = 0.622396   FTP = 0.377604\n",
      "Testing Data\n",
      "accuracy = 0.886367   precision = 0.756140   f1 = 0.664246   POD = 0.594009   FTP = 0.405991\n"
     ]
    }
   ],
   "source": [
    "# for Table S4\n",
    "print(\"Training Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(training_data_rows[0][2], training_data_rows[0][3], \n",
    "        training_data_rows[0][4], training_data_rows[0][5],\n",
    "        training_data_rows[0][6]))\n",
    "print(\"Testing Data\")\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\" \n",
    "      %(testing_data_rows[0][2], testing_data_rows[0][3], \n",
    "        testing_data_rows[0][4], testing_data_rows[0][5],\n",
    "        testing_data_rows[0][6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27797d6d",
   "metadata": {},
   "source": [
    "## Final Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee961d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.897713   precision = 0.794840   f1 = 0.698327   POD = 0.622714   FTP = 0.377286\n"
     ]
    }
   ],
   "source": [
    "# for Table 1\n",
    "print(\"accuracy = %f   precision = %f   f1 = %f   POD = %f   FTP = %f\"    \n",
    "      %(final_accuracy, final_precision, final_f1, final_pod, final_ftp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facd8e9",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b22b48a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-exc</th>\n",
       "      <th>Exc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-exc</th>\n",
       "      <td>4259</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exc</th>\n",
       "      <td>392</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Non-exc  Exc\n",
       "Non-exc     4259  167\n",
       "Exc          392  647"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matricies=confusion_matrix(label_data, final_prediction)\n",
    "columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(label_data))]]\n",
    "columns=['Non-exc','Exc']\n",
    "# columns=['Non Exceedance', 'Exceedance']\n",
    "df_cm = pd.DataFrame(confusion_matricies, index=columns, columns=columns)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9d038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
